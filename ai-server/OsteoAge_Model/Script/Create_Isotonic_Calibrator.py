# =============================================================================
# Isotonic Calibrator ìƒì„± ìŠ¤í¬ë¦½íŠ¸
# =============================================================================
# 
# ìš©ë„: ì—‘ì…€ íŒŒì¼(ëª¨ë¸ ì˜ˆì¸¡ê°’, ì˜ì‚¬ ì…ë ¥ê°’)ì„ ì½ì–´ì„œ Isotonic Calibrator ìƒì„± ë° ì €ì¥
# 
# ì‚¬ìš©ë²•:
#   1. ì—‘ì…€ íŒŒì¼ ì¤€ë¹„ (2ê°œ ì»¬ëŸ¼: model_pred, doctor_input)
#   2. ì•„ë˜ ì„¤ì •ê°’ ìˆ˜ì •
#   3. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
#   4. ìƒì„±ëœ .joblib íŒŒì¼ì„ CPU_ë‹¨ì¼~.pyì˜ ISOTONIC_CALIBRATOR_PATHì— ì§€ì •
# =============================================================================
# Calibration ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ê¸°ì¤€ (1)

# - ìµœì†Œ: 50ê°œ (EPV ì—°êµ¬ ê¸°ë°˜)
# - ê¶Œì¥: 100ê°œ ì´ìƒ
# - ì´ìƒì : 200ê°œ ì´ìƒ

# ê·¼ê±°:
# 1. Scikit-learn: Isotonicì€ ~1000ê°œ ì´ìƒì—ì„œ ì•ˆì •ì  (https://scikit-learn.org/stable/modules/calibration.html)
# 2. van Smeden et al. (2019): EPV â‰¥ 20 ê¶Œì¥ (https://pmc.ncbi.nlm.nih.gov/articles/PMC5045274/)
# 3. Ogundimu et al. (2016): EPV â‰¥ 20 ì‹œ bias ì œê±° (https://pubmed.ncbi.nlm.nih.gov/25817942/)

# * 50ê°œ ë¯¸ë§Œì—ì„œëŠ” calibration ìˆ˜í–‰ì„ ê¶Œì¥í•˜ì§€ ì•ŠìŒ (overfitting ìœ„í—˜)
# =============================================================================
# Calibration ìµœì†Œ ìƒ˜í”Œ ìˆ˜ ê¸°ì¤€ (2)
#
# Isotonic Regressionì€ non-parametric ë°©ë²•ìœ¼ë¡œ, ë°ì´í„° í¬ì¸íŠ¸ë§ˆë‹¤ 
# step functionì„ ìƒì„±í•  ìˆ˜ ìˆì–´ ì ì€ ë°ì´í„°ì—ì„œ overfitting ìœ„í—˜ì´ ë†’ìŒ.
#
# ê¶Œì¥ ê¸°ì¤€:
# - ìµœì†Œ: 100ê°œ
# - ì´ìƒì : 1000ê°œ ì´ìƒ
#
# ê·¼ê±°:
# Scikit-learn ê³µì‹ ë¬¸ì„œì— ë”°ë¥´ë©´, Isotonic calibrationì€ 
# "greater than ~1000 samples"ì—ì„œ overfittingì„ í”¼í•  ìˆ˜ ìˆë‹¤ê³  ëª…ì‹œë¨.
# https://scikit-learn.org/stable/modules/calibration.html
#
# ì›ë¬¸: "However, it is more prone to overfitting, especially on small datasets. 
#       Overall, 'isotonic' will perform as well as or better than 'sigmoid' 
#       when there is enough data (greater than ~ 1000 samples) to avoid overfitting."
#
# í˜„ì‹¤ì  ì œì•½:
# ë³‘ì› ìš´ì˜ìƒ 1000ê°œ ì¶•ì ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ, 
# ìµœì†Œ 100ê°œë¶€í„° calibrationì„ ì‹œì‘í•˜ë˜, ë°ì´í„°ê°€ ì¶•ì ë ìˆ˜ë¡ 
# ì£¼ê¸°ì ìœ¼ë¡œ re-calibrationì„ ìˆ˜í–‰í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•¨.
#
# * 100ê°œ ë¯¸ë§Œì—ì„œëŠ” calibration ìˆ˜í–‰ì„ ê¶Œì¥í•˜ì§€ ì•ŠìŒ (overfitting ìœ„í—˜)
# =============================================================================
# =============================================================================
# Calibration ìƒ˜í”Œ ìˆ˜ì— ëŒ€í•œ í˜„ì‹¤ì  ì ‘ê·¼
# =============================================================================
#
# [í•™ìˆ ì  ê·¼ê±°]
# Scikit-learn ê³µì‹ ë¬¸ì„œ: Isotonicì€ ~1000ê°œ ì´ìƒì—ì„œ overfitting ë°©ì§€
# https://scikit-learn.org/stable/modules/calibration.html
#
# [í˜„ì‹¤ì  ê³ ë ¤]
# 1. 1000ê°œ ì¶•ì ì€ ë¹„í˜„ì‹¤ì  (ë³‘ì›ë‹¹ ìˆ˜ë…„ ì†Œìš” ê°€ëŠ¥)
# 2. ëª©ì ì´ "íŠ¹ì • ì˜ì‚¬/ë³‘ì›ì— ë§ì¶¤"ì´ë©´ ì™„ë²½í•œ ì¼ë°˜í™” ë¶ˆí•„ìš”
# 3. ë„ˆë¬´ ì ìœ¼ë©´ ë…¸ì´ì¦ˆì— ë¯¼ê°í•´ì§
#
# [ì‹¤ìš©ì  ê¸°ì¤€]
# - ìµœì†Œ ì‹œì‘: 30~50ê°œ (ë‹¨, ë¶ˆì•ˆì •í•  ìˆ˜ ìˆìŒì„ ì¸ì§€)
# - ì•ˆì •ì  ìš´ì˜: 100ê°œ ì´ìƒ
# - ì£¼ê¸°ì  re-calibrationìœ¼ë¡œ ë°ì´í„° ì¶•ì ì— ë”°ë¼ ê°œì„ 
#
# * ì´ ê¸°ì¤€ì€ í•™ìˆ ì ìœ¼ë¡œ ê²€ì¦ëœ ìˆ˜ì¹˜ê°€ ì•„ë‹Œ ì‹¤ìš©ì  íƒ€í˜‘ì•ˆì„
# =============================================================================
# =============================================================================

import os
import json
import datetime
import numpy as np
import pandas as pd
from sklearn.isotonic import IsotonicRegression
from joblib import dump

# =============================================================================
# ì‚¬ìš©ì ì„¤ì • (ì—¬ê¸°ë§Œ ìˆ˜ì •)
# =============================================================================

# ì…ë ¥ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
# - ì»¬ëŸ¼ 2ê°œ: ì™¼ìª½ = ëª¨ë¸ ì˜ˆì¸¡ê°’, ì˜¤ë¥¸ìª½ = ì˜ì‚¬ ì…ë ¥ê°’
# - ì»¬ëŸ¼ëª…ì€ ììœ  (ì²« ë²ˆì§¸ ì»¬ëŸ¼ = ëª¨ë¸, ë‘ ë²ˆì§¸ ì»¬ëŸ¼ = ì˜ì‚¬)
INPUT_EXCEL_PATH = r"D:\DiWAVE\OsteoAge_Model\Data\calibration_data.xlsx"

# ì¶œë ¥ Calibrator ì €ì¥ ê²½ë¡œ
OUTPUT_CALIBRATOR_PATH = r"D:\DiWAVE\OsteoAge_Model\Calibration_Model\isotonic_calibrator.joblib"

# ìµœì†Œ ë°ì´í„° ê°œìˆ˜ (ì´ë³´ë‹¤ ì ìœ¼ë©´ ê²½ê³ )
MIN_SAMPLES_WARNING = 30  # 30ê°œ ë¯¸ë§Œì´ë©´ ê²½ê³ 
MIN_SAMPLES_ERROR = 10    # 10ê°œ ë¯¸ë§Œì´ë©´ ì—ëŸ¬

# =============================================================================
# ë©”ì¸ ë¡œì§
# =============================================================================

def create_isotonic_calibrator(excel_path: str, save_path: str) -> dict:
    """
    ì—‘ì…€ íŒŒì¼ì—ì„œ Isotonic Calibrator ìƒì„± ë° ì €ì¥
    
    Args:
        excel_path: ì…ë ¥ ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        save_path: calibrator ì €ì¥ ê²½ë¡œ (.joblib)
    
    Returns:
        dict: ê²°ê³¼ ì •ë³´
    """
    
    print("=" * 70)
    print("ğŸ”§ Isotonic Calibrator ìƒì„±")
    print("=" * 70)
    
    # 1. ì—‘ì…€ íŒŒì¼ ë¡œë“œ
    print(f"\nğŸ“‚ [STEP 1] ì—‘ì…€ íŒŒì¼ ë¡œë“œ")
    print(f"   ê²½ë¡œ: {excel_path}")
    
    if not os.path.exists(excel_path):
        print(f"   âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        return {"success": False, "error": "íŒŒì¼ ì—†ìŒ"}
    
    # ì—‘ì…€ ë˜ëŠ” CSV ë¡œë“œ
    if excel_path.endswith('.csv'):
        df = pd.read_csv(excel_path, encoding='utf-8-sig')
    else:
        df = pd.read_excel(excel_path)
    
    print(f"   âœ“ ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰, {len(df.columns)}ì—´")
    print(f"   âœ“ ì»¬ëŸ¼ëª…: {list(df.columns)}")
    
    # 2. ë°ì´í„° ì¶”ì¶œ (ì²« ë²ˆì§¸ ì»¬ëŸ¼ = ëª¨ë¸, ë‘ ë²ˆì§¸ ì»¬ëŸ¼ = ì˜ì‚¬)
    print(f"\nğŸ“Š [STEP 2] ë°ì´í„° ì¶”ì¶œ")
    
    if len(df.columns) < 2:
        print(f"   âŒ ì»¬ëŸ¼ì´ 2ê°œ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤!")
        return {"success": False, "error": "ì»¬ëŸ¼ ë¶€ì¡±"}
    
    col_model = df.columns[0]   # ì²« ë²ˆì§¸ ì»¬ëŸ¼: ëª¨ë¸ ì˜ˆì¸¡ê°’
    col_doctor = df.columns[1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼: ì˜ì‚¬ ì…ë ¥ê°’
    
    print(f"   ëª¨ë¸ ì˜ˆì¸¡ê°’ ì»¬ëŸ¼: '{col_model}'")
    print(f"   ì˜ì‚¬ ì…ë ¥ê°’ ì»¬ëŸ¼: '{col_doctor}'")
    
    # NaN ì œê±°
    df_clean = df[[col_model, col_doctor]].dropna()
    n_samples = len(df_clean)
    n_dropped = len(df) - n_samples
    
    if n_dropped > 0:
        print(f"   âš  NaN ì œê±°: {n_dropped}í–‰ ì œì™¸ë¨")
    
    print(f"   âœ“ ìœ íš¨ ë°ì´í„°: {n_samples}ê°œ")
    
    # 3. ë°ì´í„° ê°œìˆ˜ ê²€ì¦
    print(f"\nğŸ” [STEP 3] ë°ì´í„° ê°œìˆ˜ ê²€ì¦")
    
    if n_samples < MIN_SAMPLES_ERROR:
        print(f"   âŒ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤! (ìµœì†Œ {MIN_SAMPLES_ERROR}ê°œ í•„ìš”)")
        print(f"   í˜„ì¬: {n_samples}ê°œ")
        return {"success": False, "error": f"ë°ì´í„° ë¶€ì¡± ({n_samples}ê°œ)"}
    
    if n_samples < MIN_SAMPLES_WARNING:
        print(f"   âš  ê²½ê³ : ë°ì´í„°ê°€ ì ìŠµë‹ˆë‹¤. ê¶Œì¥ ìµœì†Œ {MIN_SAMPLES_WARNING}ê°œ")
        print(f"   í˜„ì¬: {n_samples}ê°œ â†’ ì‹ ë¢°ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŒ")
    else:
        print(f"   âœ“ ë°ì´í„° ê°œìˆ˜ ì¶©ë¶„: {n_samples}ê°œ")
    
    # numpy ë°°ì—´ë¡œ ë³€í™˜
    model_preds = df_clean[col_model].values.astype(np.float64)
    doctor_inputs = df_clean[col_doctor].values.astype(np.float64)
    
    # 4. ë°ì´í„° í†µê³„
    print(f"\nğŸ“ˆ [STEP 4] ë°ì´í„° í†µê³„")
    print(f"   ëª¨ë¸ ì˜ˆì¸¡ê°’ ë²”ìœ„: {model_preds.min():.1f} ~ {model_preds.max():.1f} ê°œì›”")
    print(f"   ì˜ì‚¬ ì…ë ¥ê°’ ë²”ìœ„: {doctor_inputs.min():.1f} ~ {doctor_inputs.max():.1f} ê°œì›”")
    
    diff = doctor_inputs - model_preds
    print(f"   ì°¨ì´ (ì˜ì‚¬ - ëª¨ë¸): í‰ê·  {diff.mean():+.2f}, í‘œì¤€í¸ì°¨ {diff.std():.2f} ê°œì›”")
    
    mae_before = np.mean(np.abs(diff))
    print(f"   ë³´ì • ì „ MAE: {mae_before:.2f} ê°œì›”")
    
    # 5. Isotonic Regression í•™ìŠµ
    print(f"\nğŸ¯ [STEP 5] Isotonic Regression í•™ìŠµ")
    
    calibrator = IsotonicRegression(out_of_bounds='clip')
    calibrator.fit(model_preds, doctor_inputs)
    
    print(f"   âœ“ í•™ìŠµ ì™„ë£Œ")
    
    # ë³´ì • í›„ MAE ê³„ì‚°
    calibrated_preds = calibrator.predict(model_preds)
    mae_after = np.mean(np.abs(doctor_inputs - calibrated_preds))
    mae_improvement = mae_before - mae_after
    
    print(f"   âœ“ ë³´ì • í›„ MAE: {mae_after:.2f} ê°œì›”")
    print(f"   âœ“ MAE ê°œì„ : {mae_improvement:+.2f} ê°œì›” ({mae_improvement/mae_before*100:.1f}% ê°ì†Œ)")
    
    # 6. Calibrator ì €ì¥
    print(f"\nğŸ’¾ [STEP 6] Calibrator ì €ì¥")
    
    # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    save_dir = os.path.dirname(save_path)
    if save_dir and not os.path.exists(save_dir):
        os.makedirs(save_dir, exist_ok=True)
    
    # joblibìœ¼ë¡œ ì €ì¥
    dump(calibrator, save_path)
    print(f"   âœ“ ì €ì¥ ì™„ë£Œ: {save_path}")
    
    # ë©”íƒ€ë°ì´í„° ì €ì¥
    meta_path = save_path.replace('.joblib', '_meta.json')
    meta = {
        "type": "isotonic_regression",
        "created_at": datetime.datetime.now().isoformat(),
        "source_file": os.path.basename(excel_path),
        "n_samples": int(n_samples),
        "model_pred_range": [float(model_preds.min()), float(model_preds.max())],
        "doctor_input_range": [float(doctor_inputs.min()), float(doctor_inputs.max())],
        "mae_before": float(mae_before),
        "mae_after": float(mae_after),
        "mae_improvement": float(mae_improvement),
        "mae_improvement_pct": float(mae_improvement / mae_before * 100),
    }
    
    with open(meta_path, 'w', encoding='utf-8') as f:
        json.dump(meta, f, ensure_ascii=False, indent=2)
    
    print(f"   âœ“ ë©”íƒ€ë°ì´í„° ì €ì¥: {meta_path}")
    
    # 7. ì™„ë£Œ
    print("\n" + "=" * 70)
    print("âœ… Calibrator ìƒì„± ì™„ë£Œ!")
    print("=" * 70)
    print(f"\n   ğŸ“ Calibrator íŒŒì¼: {save_path}")
    print(f"   ğŸ“Š í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {n_samples}ê°œ")
    print(f"   ğŸ“‰ MAE ê°œì„ : {mae_before:.2f} â†’ {mae_after:.2f} ê°œì›”")
    print(f"\n   ğŸ’¡ ì‚¬ìš©ë²•:")
    print(f"      CPU_ë‹¨ì¼~.pyì—ì„œ:")
    print(f"      USE_ISOTONIC_CALIBRATION = True")
    print(f"      ISOTONIC_CALIBRATOR_PATH = r\"{save_path}\"")
    print("=" * 70)
    
    return {
        "success": True,
        "calibrator_path": save_path,
        "meta_path": meta_path,
        "n_samples": n_samples,
        "mae_before": mae_before,
        "mae_after": mae_after,
        "mae_improvement": mae_improvement,
    }


# =============================================================================
# í…ŒìŠ¤íŠ¸ìš©: ìƒ˜í”Œ ì—‘ì…€ íŒŒì¼ ìƒì„± (ì‹¤ì œ ì‚¬ìš© ì‹œ ì£¼ì„ ì²˜ë¦¬)
# =============================================================================

def create_sample_excel(output_path: str, n_samples: int = 50):
    """
    í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ì—‘ì…€ íŒŒì¼ ìƒì„±
    """
    np.random.seed(42)
    
    # ëª¨ë¸ì´ ì•½ê°„ ê³¼ì†Œì˜ˆì¸¡í•˜ëŠ” ì‹œë‚˜ë¦¬ì˜¤
    true_values = np.random.uniform(80, 200, n_samples)
    model_preds = true_values - 5 + np.random.normal(0, 8, n_samples)  # í‰ê·  5ê°œì›” ê³¼ì†Œì˜ˆì¸¡
    
    df = pd.DataFrame({
        'model_pred': model_preds,
        'doctor_input': true_values
    })
    
    df.to_excel(output_path, index=False)
    print(f"ìƒ˜í”Œ ì—‘ì…€ ìƒì„±: {output_path} ({n_samples}í–‰)")
    return output_path


# =============================================================================
# ì‹¤í–‰
# =============================================================================

if __name__ == "__main__":
    
    # ìƒ˜í”Œ ì—‘ì…€ì´ ì—†ìœ¼ë©´ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
    if not os.path.exists(INPUT_EXCEL_PATH):
        print(f"âš  ì…ë ¥ íŒŒì¼ì´ ì—†ì–´ì„œ ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
        print(f"   ì‹¤ì œ ì‚¬ìš© ì‹œ INPUT_EXCEL_PATHë¥¼ ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ë³€ê²½í•˜ì„¸ìš”.\n")
        
        # ìƒ˜í”Œ ìƒì„±
        sample_path = INPUT_EXCEL_PATH.replace('.xlsx', '_sample.xlsx')
        create_sample_excel(sample_path, n_samples=50)
        INPUT_EXCEL_PATH_USE = sample_path
    else:
        INPUT_EXCEL_PATH_USE = INPUT_EXCEL_PATH
    
    # Calibrator ìƒì„±
    result = create_isotonic_calibrator(
        excel_path=INPUT_EXCEL_PATH_USE,
        save_path=OUTPUT_CALIBRATOR_PATH
    )
    
    if result['success']:
        print(f"\nğŸ‰ ì„±ê³µ! ì´ì œ CPU_ë‹¨ì¼~.pyì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        print(f"\nâŒ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")
