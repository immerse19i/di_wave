"""
BoneAge + PAH + ìœ ì „/ì„±ìˆ™ë„ ë³´ì • í†µí•© ëª¨ë“ˆ (Refactored Version)

[í™˜ê²½ êµ¬ì„±]
ê°€ìƒí™˜ê²½: conda create -n boneage-cpu python=3.10 -y && conda activate boneage-cpu
íŒ¨í‚¤ì§€: pip install -r requirements.txt

[ì‚¬ìš© ë°©ë²•]
1. ë‹¨ë… ì‹¤í–‰: python CPU_BoneAge_PAH_Compact.py
2. ëª¨ë“ˆ import:
   from CPU_BoneAge_PAH_Compact import predict_bone_age
   result = predict_bone_age(image_path, sex, height, age_months, father_height, mother_height)
"""
import os
import json
import math
import numpy as np
import pandas as pd
import cv2
import torch
import torch.nn as nn
from torchvision import transforms
import timm
from statistics import NormalDist

# =============================================================================
# ê²½ë¡œ ì„¤ì • (ìƒëŒ€ê²½ë¡œ ê¸°ë°˜)
# =============================================================================
# ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸°
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)  # Script í´ë”ì˜ ìƒìœ„ = OsteoAge_Model

# ë°ì´í„° ê²½ë¡œ
DATA_DIR = os.path.join(PROJECT_ROOT, "Data")
LMS_CSV_PATH = os.path.join(DATA_DIR, "LMS.csv")
CRITERIA_JSON_PATH = os.path.join(DATA_DIR, "criteria_C1C2A_20251027_102144.json")

# ëª¨ë¸ ê²½ë¡œ
MODEL_DIR = os.path.join(PROJECT_ROOT, "Model9_ROI")
MODEL_NAME = "ConvNeXt_Base_BoneAge_FiLM_Late_PROMISING_Stage2_3_Reso_NoTTA_ROI"
MODEL_PATHS = [os.path.join(MODEL_DIR, f"{MODEL_NAME}_fold{i}.pth") for i in range(1, 6)]
WEIGHT_PATH = os.path.join(MODEL_DIR, f"{MODEL_NAME}_ensemble_weights_from_OOF.json")

# Calibration ëª¨ë¸ ê²½ë¡œ
CALIBRATION_DIR = os.path.join(PROJECT_ROOT, "Calibration_Model")
ISOTONIC_CALIBRATOR_PATH = os.path.join(CALIBRATION_DIR, "isotonic_calibrator.joblib")

# =============================================================================
# ê³ ì • ì„¤ì • (ë³€ê²½ ë¶ˆí•„ìš”)
# =============================================================================
BONEAGE_MAX_DEVIATION = 24
ADULT_MONTHS = 216.0
PAH_W_D = 0.4
PAH_ALPHA = 0.1
IMG_SIZE = 448
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ê¸°ë³¸ ì„¤ì •
DEFAULT_PREPROCESS_CONFIG = {
    "do_standardize": True,
    "do_roi": True,
    "use_std1": True,
    "use_roi1": False,
    "use_std2": False,
    "use_roi2": False,
    "use_isotonic_calibration": True
}

# ROI íŒŒë¼ë¯¸í„°
CROP_PCT = 10
PREPROC_MODE, BILAT_D, BILAT_SIGMA_COLOR, BILAT_SIGMA_SPACE = 2, 6, 96, 97
MEDIAN_K, GAUSS_K, CLAHE_CLIP, CLAHE_TILE = 9, 8, 8, 6
THRESH_MODE, BLOCK_SIZE_RAW, C_SHIFTED, GLOBAL_T, INVERT = 1, 40, 109, 123, 1
C_ACTUAL = C_SHIFTED - 100
OPEN_KS, CLOSE_KS, ERODE_KS, DILATE_KS = 5, 59, 0, 61
MORPH_ITER, FILL_HOLES = 1, 0
MIN_AREA_PCT, MAX_AREA_PCT, CENTRAL_WINDOW_PCT = 10, 100, 0
SELECTION_MODE, W_AREA, W_LENGTH, W_SOLIDITY, W_CENTER, CENTRAL_BIAS = 0, 20, 70, 10, 30, 10
APPLY_MASK_INSIDE_CROP, CROP_MARGIN = True, 0

# =============================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================
def imread_unicode(path, flags=cv2.IMREAD_GRAYSCALE):
    """ìœ ë‹ˆì½”ë“œ ê²½ë¡œ ì§€ì› ì´ë¯¸ì§€ ë¡œë“œ"""
    img = cv2.imdecode(np.fromfile(path, dtype=np.uint8), flags)
    if img is None:
        raise FileNotFoundError(f"Failed to load image: {path}")
    return img


def imread_unicode_color(path):
    """ìœ ë‹ˆì½”ë“œ ê²½ë¡œ ì§€ì› ì»¬ëŸ¬ ì´ë¯¸ì§€ ë¡œë“œ"""
    return imread_unicode(path, cv2.IMREAD_COLOR)


def to_uint8(img):
    """ì´ë¯¸ì§€ë¥¼ uint8ë¡œ ë³€í™˜"""
    return np.clip(img, 0, 255).astype(np.uint8)


def to_bgr(img):
    """ì´ë¯¸ì§€ë¥¼ BGR í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if img is None:
        return None
    if img.ndim == 2:
        return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    if img.shape[2] == 4:
        return cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)
    return img


def load_criteria(path):
    """ì „ì²˜ë¦¬ ê¸°ì¤€ JSON ë¡œë“œ"""
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)


def rotate_bound(gray, angle_deg):
    """ì´ë¯¸ì§€ íšŒì „"""
    h, w = gray.shape[:2]
    M = cv2.getRotationMatrix2D((w/2, h/2), angle_deg, 1.0)
    return cv2.warpAffine(gray, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)


def apply_alignment(gray, crit):
    """ì •ë ¬ ë° ë¦¬ì‚¬ì´ì¦ˆ ì ìš©"""
    out = gray
    align = crit.get("align", {})
    if "rotate_deg" in align:
        out = rotate_bound(out, float(align["rotate_deg"]))
    resize = crit.get("resize", {})
    if "short" in resize:
        short = int(resize["short"])
        h, w = out.shape[:2]
        cur_short = min(h, w)
        if cur_short > 0 and short > 0 and cur_short != short:
            scale = short / float(cur_short)
            out = cv2.resize(out, (max(1, int(round(w*scale))), max(1, int(round(h*scale)))), interpolation=cv2.INTER_LINEAR)
    return out


def crop_by_roi(gray, crit):
    """ROI ì˜ì—­ ì¶”ì¶œ"""
    roi = crit.get("roi", None)
    if roi is None:
        return gray
    h, w = gray.shape[:2]
    rtype = (roi.get("type") or "relative").lower()
    if rtype == "relative":
        x, y = int(round(float(roi["x"])*w)), int(round(float(roi["y"])*h))
        ww, hh = int(round(float(roi["w"])*w)), int(round(float(roi["h"])*h))
    else:
        x, y = int(round(float(roi["x"]))), int(round(float(roi["y"])))
        ww, hh = int(round(float(roi["w"]))), int(round(float(roi["h"])))
    x1, y1 = max(0, min(w, x)), max(0, min(h, y))
    x2, y2 = max(0, min(w, x+ww)), max(0, min(h, y+hh))
    if x2 > x1 and y2 > y1:
        return gray[y1:y2, x1:x2]
    return gray


def apply_intensity_mapping(gray, crit):
    """ë°ê¸° ë§¤í•‘ ì ìš©"""
    g = gray.astype(np.float32)
    inten = crit.get("intensity", {})
    src_lo = float(inten.get("src_lo", np.percentile(g, 1)))
    src_hi = float(inten.get("src_hi", np.percentile(g, 99)))
    dst_lo = float(inten.get("dst_lo", 0.0))
    dst_hi = float(inten.get("dst_hi", 255.0))
    if src_hi <= src_lo:
        src_hi = src_lo + 1.0
    g = np.clip((g - src_lo) / (src_hi - src_lo), 0.0, 1.0) * (dst_hi - dst_lo) + dst_lo
    gamma = crit.get("gamma", None)
    if gamma:
        g = np.power(np.clip(g/255.0, 0, 1), float(gamma)) * 255.0
    return to_uint8(g)


def standardize_gray_array(gray, criteria):
    """ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€ í‘œì¤€í™”"""
    g = apply_alignment(gray, criteria)
    g = crop_by_roi(g, criteria)
    g = apply_intensity_mapping(g, criteria)
    return g


def standardize_bgr(bgr_img, criteria):
    """BGR ì´ë¯¸ì§€ í‘œì¤€í™”"""
    gray = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)
    g_std = standardize_gray_array(gray, criteria)
    return to_bgr(g_std)


# =============================================================================
# ROI ì¶”ì¶œ í•¨ìˆ˜
# =============================================================================
def oddize(x, min_odd=3):
    """í™€ìˆ˜ë¡œ ë³€í™˜"""
    x = int(max(x, min_odd))
    return x if x % 2 == 1 else x + 1


def contour_center(c):
    """ì»¨íˆ¬ì–´ ì¤‘ì‹¬ ê³„ì‚°"""
    M = cv2.moments(c)
    if M["m00"] != 0:
        return np.array([M["m10"]/M["m00"], M["m01"]/M["m00"]], dtype=np.float32)
    return c.reshape(-1, 2).astype(np.float32).mean(axis=0)


def solidity(c):
    """ì†”ë¦¬ë””í‹° ê³„ì‚°"""
    area = cv2.contourArea(c)
    hull_area = max(cv2.contourArea(cv2.convexHull(c)), 1e-6)
    return float(area) / hull_area


def in_central_window(ctr, w, h, pct):
    """ì¤‘ì•™ ì˜ì—­ ë‚´ ì—¬ë¶€ í™•ì¸"""
    if pct <= 0:
        return True
    cx0 = w*(100-pct)/200
    cy0 = h*(100-pct)/200
    return (cx0 <= ctr[0] <= w-cx0) and (cy0 <= ctr[1] <= h-cy0)


def pick_contour(contours, img_w, img_h, min_area, max_area, mode, w_area, w_len, w_sol, w_center, central_bias, central_win_pct):
    """ìµœì  ì»¨íˆ¬ì–´ ì„ íƒ"""
    cand = []
    for c in contours:
        a = cv2.contourArea(c)
        if min_area <= a <= max_area and in_central_window(contour_center(c), img_w, img_h, central_win_pct):
            cand.append(c)
    if not cand:
        return None
    if mode == 1:
        return cand[int(np.argmax([cv2.contourArea(c) for c in cand]))]
    if mode == 2:
        return cand[int(np.argmax([cv2.arcLength(c, True) for c in cand]))]
    
    areas = np.array([cv2.contourArea(c) for c in cand], dtype=np.float32)
    perims = np.array([cv2.arcLength(c, True) for c in cand], dtype=np.float32)
    solids = np.array([solidity(c) for c in cand], dtype=np.float32)
    ctrs = np.array([contour_center(c) for c in cand], dtype=np.float32)
    diag = np.hypot(img_w, img_h)
    dists = np.hypot(ctrs[:,0]-img_w/2, ctrs[:,1]-img_h/2) / (diag + 1e-6)
    
    if mode == 3:
        return cand[int(np.argmin(dists))]
    if mode == 4:
        return cand[int(np.argmax(solids))]
    
    a_norm = areas / (areas.max() + 1e-6)
    l_norm = perims / (perims.max() + 1e-6)
    score = (w_area*a_norm + w_len*l_norm + w_sol*solids) - (w_center*(central_bias/50.0)*dists)
    return cand[int(np.argmax(score))]


def apply_preproc(gray, pre_mode, bilat_d, sigC, sigS, med_k, gau_k, clahe_clip, clahe_tile):
    """ì „ì²˜ë¦¬ í•„í„° ì ìš©"""
    if pre_mode == 1 and bilat_d > 0:
        return cv2.bilateralFilter(gray, d=int(bilat_d), sigmaColor=int(sigC), sigmaSpace=int(sigS))
    if pre_mode == 2:
        return cv2.medianBlur(gray, oddize(max(1, int(med_k))))
    if pre_mode == 3:
        k = oddize(max(1, int(gau_k)))
        return cv2.GaussianBlur(gray, (k, k), 0)
    if pre_mode == 4:
        clahe = cv2.createCLAHE(clipLimit=max(1.0, float(clahe_clip)), tileGridSize=(max(2, int(clahe_tile)), max(2, int(clahe_tile))))
        return clahe.apply(gray.astype(np.uint8))
    return gray


def apply_threshold(gray, mode, block_size, Cval, invert, global_t):
    """ì´ì§„í™” ì ìš©"""
    if mode in (0, 1):
        block = oddize(int(block_size), 3)
        max_odd = (min(gray.shape[:2]) // 2) * 2 - 1
        if max_odd >= 3 and block > max_odd:
            block = oddize(max_odd)
        method = cv2.ADAPTIVE_THRESH_MEAN_C if mode == 0 else cv2.ADAPTIVE_THRESH_GAUSSIAN_C
        thtype = cv2.THRESH_BINARY_INV if invert == 1 else cv2.THRESH_BINARY
        return cv2.adaptiveThreshold(gray, 255, method, thtype, block, int(Cval))
    if mode == 2:
        t = int(np.clip(global_t, 0, 255))
        _, b = cv2.threshold(gray, t, 255, cv2.THRESH_BINARY_INV if invert == 1 else cv2.THRESH_BINARY)
        return b
    flag = (cv2.THRESH_BINARY_INV if invert == 1 else cv2.THRESH_BINARY) | cv2.THRESH_OTSU
    _, b = cv2.threshold(gray, 0, 255, flag)
    return b


def apply_morph(bin_img, open_k, close_k, erode_k, dilate_k, iters, fill_holes):
    """í˜•íƒœí•™ì  ì—°ì‚° ì ìš©"""
    out = bin_img.copy()
    def ker(k):
        return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (int(k), int(k)))
    if open_k > 0:
        for _ in range(max(1, int(iters))):
            out = cv2.morphologyEx(out, cv2.MORPH_OPEN, ker(open_k))
    if close_k > 0:
        for _ in range(max(1, int(iters))):
            out = cv2.morphologyEx(out, cv2.MORPH_CLOSE, ker(close_k))
    if erode_k > 0:
        for _ in range(max(1, int(iters))):
            out = cv2.erode(out, ker(erode_k))
    if dilate_k > 0:
        for _ in range(max(1, int(iters))):
            out = cv2.dilate(out, ker(dilate_k))
    if fill_holes == 1:
        h, w = out.shape[:2]
        flood = out.copy()
        mask = np.zeros((h+2, w+2), np.uint8)
        cv2.floodFill(flood, mask, (0, 0), 255 if out[0, 0] == 0 else 0)
        out = cv2.bitwise_or(out, cv2.bitwise_not(flood))
    return out


def extract_roi_from_image(bgr_img):
    """ì´ë¯¸ì§€ì—ì„œ ROI ì¶”ì¶œ"""
    if bgr_img is None:
        return None, "read_fail"
    gray_full = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)
    H, W = gray_full.shape[:2]
    ph, pw = int(H*(CROP_PCT/100.0)), int(W*(CROP_PCT/100.0))
    
    if ph*2 >= H or pw*2 >= W:
        y0, y1, x0, x1 = 0, H, 0, W
        crop_gray = gray_full
        bgr_crop = bgr_img
    else:
        y0, y1 = ph, H-ph
        x0, x1 = pw, W-pw
        crop_gray = gray_full[y0:y1, x0:x1]
        bgr_crop = bgr_img[y0:y1, x0:x1]
    
    crop_gray = cv2.normalize(crop_gray, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    crop_gray = apply_preproc(crop_gray, PREPROC_MODE, BILAT_D, BILAT_SIGMA_COLOR, BILAT_SIGMA_SPACE, MEDIAN_K, GAUSS_K, CLAHE_CLIP, CLAHE_TILE)
    bin_img = apply_threshold(crop_gray, THRESH_MODE, BLOCK_SIZE_RAW, C_ACTUAL, INVERT, GLOBAL_T)
    bin_img = apply_morph(bin_img, OPEN_KS, CLOSE_KS, ERODE_KS, DILATE_KS, MORPH_ITER, FILL_HOLES)
    
    contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not contours:
        return None, "no_contour"
    
    h, w = bin_img.shape[:2]
    min_area = (MIN_AREA_PCT/100.0) * (h*w)
    max_area = (MAX_AREA_PCT/100.0) * (h*w)
    best = pick_contour(contours, w, h, min_area, max_area, SELECTION_MODE, W_AREA/100.0, W_LENGTH/100.0, W_SOLIDITY/100.0, W_CENTER/100.0, CENTRAL_BIAS, CENTRAL_WINDOW_PCT)
    
    if best is None:
        return None, "no_valid_contour"
    
    bx, by, bw, bh = cv2.boundingRect(best)
    if CROP_MARGIN > 0:
        bx = max(0, bx - CROP_MARGIN)
        by = max(0, by - CROP_MARGIN)
        bw = min(w - bx, bw + 2*CROP_MARGIN)
        bh = min(h - by, bh + 2*CROP_MARGIN)
    
    crop_roi = bgr_crop[by:by+bh, bx:bx+bw].copy()
    if APPLY_MASK_INSIDE_CROP:
        mask = np.zeros((h, w), np.uint8)
        cv2.drawContours(mask, [best], -1, 255, thickness=cv2.FILLED)
        crop_mask = mask[by:by+bh, bx:bx+bw]
        crop_roi = cv2.bitwise_and(crop_roi, crop_roi, mask=crop_mask)
    return crop_roi, "ok"


# =============================================================================
# ëª¨ë¸ ì •ì˜ ë° ì¶”ë¡ 
# =============================================================================
class ConvNeXtFiLM_Late_MT(nn.Module):
    """ConvNeXt + FiLM ê¸°ë°˜ ë¼ˆë‚˜ì´ ì˜ˆì¸¡ ëª¨ë¸"""
    def __init__(self, num_bins=7):
        super().__init__()
        self.backbone = timm.create_model("convnext_base", pretrained=False, num_classes=0, in_chans=3)
        for m in self.backbone.modules():
            if isinstance(m, nn.BatchNorm2d):
                m.eval()
        nf = self.backbone.num_features
        self.sex_emb = nn.Embedding(2, 32)
        self.gamma_fc = nn.Linear(32, nf)
        self.beta_fc = nn.Linear(32, nf)
        self.head_reg = nn.Sequential(nn.LayerNorm(nf), nn.Linear(nf, 256), nn.GELU(), nn.Dropout(0.3), nn.Linear(256, 1))
        self.head_cls = nn.Sequential(nn.LayerNorm(nf), nn.Linear(nf, 256), nn.GELU(), nn.Dropout(0.3), nn.Linear(256, num_bins))
        self.num_bins = num_bins

    def forward(self, img, sex):
        x = self.backbone.forward_features(img)
        x = x.mean(dim=[2, 3])
        s = self.sex_emb(sex)
        gamma = self.gamma_fc(s)
        beta = self.beta_fc(s)
        x = gamma * x + beta
        pred_reg = self.head_reg(x).squeeze(1)
        logits = self.head_cls(x)
        return pred_reg, logits


def infer_cls_bins_from_state_dict(state_dict):
    """ëª¨ë¸ ê°€ì¤‘ì¹˜ì—ì„œ ë¶„ë¥˜ í—¤ë“œ í¬ê¸° ì¶”ë¡ """
    cands = [int(w.shape[0]) for k, w in state_dict.items() if k.startswith("head_cls.") and w.dim() == 2]
    return min(cands) if cands else None


def load_single_model(path, device):
    """ë‹¨ì¼ ëª¨ë¸ ë¡œë“œ"""
    if not os.path.exists(path):
        raise FileNotFoundError(f"Model not found: {path}")
    sd = torch.load(path, map_location=device)
    k = infer_cls_bins_from_state_dict(sd)
    if k is None:
        model = ConvNeXtFiLM_Late_MT(num_bins=7).to(device)
        filt = {kk: vv for kk, vv in sd.items() if not kk.startswith("head_cls.")}
        model.load_state_dict(filt, strict=False)
    else:
        model = ConvNeXtFiLM_Late_MT(num_bins=k).to(device)
        try:
            model.load_state_dict(sd, strict=True)
        except RuntimeError:
            filt = {kk: vv for kk, vv in sd.items() if not kk.startswith("head_cls.")}
            model.load_state_dict(filt, strict=False)
    model.eval()
    return model


def load_fold_models(device, model_paths):
    """5-Fold ëª¨ë¸ ë¡œë“œ"""
    models = []
    ks = []
    for p in model_paths:
        m = load_single_model(p, device)
        models.append(m)
        ks.append(m.num_bins)
    if len(set(ks)) > 1:
        print(f"[WARN] Different head_cls K: {ks}")
    else:
        print(f"[INFO] head_cls K={ks[0]}")
    return models


@torch.no_grad()
def ensemble_predict_single(bgr_img, sex, models, weights, device, img_size=IMG_SIZE):
    """ì•™ìƒë¸” ì˜ˆì¸¡ ìˆ˜í–‰"""
    rgb = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2RGB)
    tfm = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    x = tfm(rgb).unsqueeze(0).to(device)
    s = torch.tensor([int(sex)], dtype=torch.long, device=device)
    outs = []
    for m in models:
        pr, _ = m(x, s)
        outs.append(pr.float().cpu().numpy())
    outs = np.stack(outs, axis=0)
    pred = float(np.average(outs, axis=0, weights=weights)[0])
    return pred


def clamp_boneage(pred, age_current, max_dev=BONEAGE_MAX_DEVIATION):
    """ë¼ˆë‚˜ì´ ë²”ìœ„ ì œí•œ"""
    lo = age_current - max_dev
    hi = age_current + max_dev
    if pred < lo:
        return lo, True, pred
    if pred > hi:
        return hi, True, pred
    return pred, False, pred


# =============================================================================
# LMS ê¸°ë°˜ PAH ê³„ì‚°
# =============================================================================
def normalize_sex_value(v):
    """ì„±ë³„ ê°’ ì •ê·œí™”"""
    if pd.isna(v):
        return None
    s = str(v).strip().lower()
    if s in ["1", "m", "male", "ë‚¨", "boy"]:
        return "male"
    if s in ["2", "f", "female", "ì—¬", "girl"]:
        return "female"
    return None


def z_from_x(x, L, M, S):
    """í‚¤ì—ì„œ Z-score ê³„ì‚°"""
    if abs(L) < 1e-12:
        return np.log(x/M) / S
    return ((x/M)**L - 1.0) / (L*S)


def x_from_z(z, L, M, S):
    """Z-scoreì—ì„œ í‚¤ ê³„ì‚°"""
    if abs(L) < 1e-12:
        return M * np.exp(S*z)
    return M * (1.0 + L*S*z)**(1.0/L)


def load_lms_data(csv_path):
    """LMS ë°ì´í„° ë¡œë“œ"""
    df = pd.read_csv(csv_path)
    df["sex_std"] = df["Sex"].apply(normalize_sex_value)
    return df


def get_lms_interpolators(lms_df, sex):
    """LMS ë³´ê°„ í•¨ìˆ˜ ìƒì„±"""
    sex_std = "male" if sex == 1 else "female"
    df = lms_df[lms_df["sex_std"] == sex_std][["Month", "L", "M", "S"]].dropna().sort_values("Month").reset_index(drop=True)
    if df.empty:
        raise ValueError(f"No data for {sex_std}")
    months = df["Month"].values.astype(float)
    Lv = df["L"].values.astype(float)
    Mv = df["M"].values.astype(float)
    Sv = df["S"].values.astype(float)
    
    def interp(t, ys):
        t_clipped = np.clip(t, months.min(), months.max())
        return float(np.interp(t_clipped, months, ys))
    
    return lambda t: interp(t, Lv), lambda t: interp(t, Mv), lambda t: interp(t, Sv)


def calculate_pah_lms(height, boneage_months, sex, lms_df, adult_months=216.0):
    """LMS ê¸°ë°˜ PAH ê³„ì‚°"""
    L_fn, M_fn, S_fn = get_lms_interpolators(lms_df, sex)
    L_ba, M_ba, S_ba = L_fn(boneage_months), M_fn(boneage_months), S_fn(boneage_months)
    Z_ba = z_from_x(height, L_ba, M_ba, S_ba)
    percentile_ba = NormalDist().cdf(Z_ba) * 100.0
    L_ad, M_ad, S_ad = L_fn(adult_months), M_fn(adult_months), S_fn(adult_months)
    pah_lms = x_from_z(Z_ba, L_ad, M_ad, S_ad)
    return {
        "Z_score_boneage": Z_ba,
        "percentile_boneage": percentile_ba,
        "PAH_LMS": pah_lms,
        "L_ba": L_ba, "M_ba": M_ba, "S_ba": S_ba,
        "L_ad": L_ad, "M_ad": M_ad, "S_ad": S_ad
    }


def calculate_height_percentile(height, age_months, sex, lms_df):
    """í˜„ì¬ í‚¤ ë°±ë¶„ìœ„ ê³„ì‚°"""
    L_fn, M_fn, S_fn = get_lms_interpolators(lms_df, sex)
    L_ca, M_ca, S_ca = L_fn(age_months), M_fn(age_months), S_fn(age_months)
    Z_ca = z_from_x(height, L_ca, M_ca, S_ca)
    percentile_ca = NormalDist().cdf(Z_ca) * 100.0
    return {
        "Z_score_current": Z_ca,
        "percentile_current": percentile_ca
    }


def calculate_pah_final_percentile(pah_final, sex, lms_df, adult_months=216.0):
    """ìµœì¢… PAH ë°±ë¶„ìœ„ ê³„ì‚°"""
    L_fn, M_fn, S_fn = get_lms_interpolators(lms_df, sex)
    L_ad, M_ad, S_ad = L_fn(adult_months), M_fn(adult_months), S_fn(adult_months)
    Z_pah = z_from_x(pah_final, L_ad, M_ad, S_ad)
    percentile_pah = NormalDist().cdf(Z_pah) * 100.0
    return {
        "Z_score_pah_final": Z_pah,
        "percentile_pah_final": percentile_pah
    }


def calculate_mph_percentile(mph, sex, lms_df, adult_months=216.0):
    """MPH(ìœ ì „ ê¸°ë°˜ ì˜ˆì¸¡ í‚¤) ë°±ë¶„ìœ„ ê³„ì‚°"""
    L_fn, M_fn, S_fn = get_lms_interpolators(lms_df, sex)
    L_ad, M_ad, S_ad = L_fn(adult_months), M_fn(adult_months), S_fn(adult_months)
    Z_mph = z_from_x(mph, L_ad, M_ad, S_ad)
    percentile_mph = NormalDist().cdf(Z_mph) * 100.0
    return {
        "Z_score_mph": Z_mph,
        "percentile_mph": percentile_mph
    }


def calculate_pah_lms_percentile(pah_lms, sex, lms_df, adult_months=216.0):
    """PAH_LMS(ì„±ì¥ê³¡ì„  ê¸°ë°˜ ì˜ˆì¸¡ í‚¤) ë°±ë¶„ìœ„ ê³„ì‚°"""
    L_fn, M_fn, S_fn = get_lms_interpolators(lms_df, sex)
    L_ad, M_ad, S_ad = L_fn(adult_months), M_fn(adult_months), S_fn(adult_months)
    Z_pah_lms = z_from_x(pah_lms, L_ad, M_ad, S_ad)
    percentile_pah_lms = NormalDist().cdf(Z_pah_lms) * 100.0
    return {
        "Z_score_pah_lms": Z_pah_lms,
        "percentile_pah_lms": percentile_pah_lms
    }


def months_to_year_month_str(months):
    """ê°œì›”ì„ 'YY MM' í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    months_int = int(round(months))
    years = months_int // 12
    remaining_months = months_int % 12
    return f"{years}Y {remaining_months}M"


def calculate_potential_score(age_current_month, boneage_month):
    """ì„±ì¥ ì ì¬ë ¥ ì ìˆ˜ ê³„ì‚°"""
    delta = age_current_month - boneage_month
    delta_clamped = max(-24.0, min(24.0, delta))
    score = ((delta_clamped + 24.0) / 48.0) * 100.0
    if score >= 70:
        interp = "ë†’ìŒ"
    elif score >= 55:
        interp = "ì•½ê°„ ë†’ìŒ"
    elif score >= 45:
        interp = "í‰ê· "
    elif score >= 30:
        interp = "ì•½ê°„ ë‚®ìŒ"
    else:
        interp = "ë‚®ìŒ"
    return {
        "delta_boneage": delta,
        "delta_boneage_clamped": delta_clamped,
        "potential_score": score,
        "interpretation": interp
    }


# =============================================================================
# PAH ë³´ì • (ìœ ì „/ì„±ìˆ™ë„)
# =============================================================================
def is_valid_height(h):
    """ìœ íš¨í•œ í‚¤ ê°’ í™•ì¸"""
    if h is None:
        return False
    if isinstance(h, str):
        return h.upper() not in ["NA", "NAN", "NONE", ""]
    return not pd.isna(h)


def calculate_mph(father, mother, male):
    """MPH(ìœ ì „ ê¸°ë°˜ ì˜ˆì¸¡ í‚¤) ê³„ì‚°"""
    mph_mean = (father + mother) / 2.0
    return mph_mean + 6.5 if male == 1 else mph_mean - 6.5


def calibrate_pah(height, pah_lms, father_height, mother_height, male, age_current_month, boneage_month, w_D=PAH_W_D, alpha=PAH_ALPHA):
    """PAH ë³´ì • (ìœ ì „/ì„±ìˆ™ë„)"""
    can_use_genetic = is_valid_height(father_height) and is_valid_height(mother_height)
    R_LMS = pah_lms - height
    Gap_year = (boneage_month - age_current_month) / 12.0
    
    result = {
        "R_LMS": R_LMS,
        "MPH": None,
        "D_target": None,
        "Gap_year": Gap_year,
        "R_gen": None,
        "PAH_Genetic": None,
        "Î”Genetic": 0.0,
        "Î”Maturity": None,
        "R_final": None,
        "PAH_Final": None,
        "genetic_available": can_use_genetic
    }
    
    if can_use_genetic:
        MPH = calculate_mph(float(father_height), float(mother_height), male)
        D_target = max(MPH - height, 0.0)
        R_gen = (1.0 - w_D) * R_LMS + w_D * D_target
        result["MPH"] = MPH
        result["D_target"] = D_target
        result["R_gen"] = R_gen
        result["PAH_Genetic"] = height + R_gen
        result["Î”Genetic"] = R_gen - R_LMS
        
        gap_factor = 1.0 - alpha * Gap_year
        R_final = max(R_gen * gap_factor, 0.0)
        result["R_final"] = R_final
        result["Î”Maturity"] = R_final - R_gen
        result["PAH_Final"] = height + R_final
    else:
        gap_factor = 1.0 - alpha * Gap_year
        R_final = max(R_LMS * gap_factor, 0.0)
        result["R_final"] = R_final
        result["Î”Maturity"] = R_final - R_LMS
        result["PAH_Final"] = height + R_final
    
    return result


# =============================================================================
# ëª¨ë¸ ìºì‹œ (ì‹±ê¸€í†¤ íŒ¨í„´)
# =============================================================================
_model_cache = {
    "models": None,
    "weights": None,
    "criteria": None,
    "lms_df": None,
    "calibrator": None
}


def load_resources(force_reload=False):
    """
    ëª¨ë¸ ë° ë°ì´í„° ë¦¬ì†ŒìŠ¤ ë¡œë“œ (ìºì‹±)
    
    Parameters:
        force_reload: Trueì´ë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ë‹¤ì‹œ ë¡œë“œ
    
    Returns:
        dict: ë¡œë“œëœ ë¦¬ì†ŒìŠ¤ë“¤
    """
    global _model_cache
    
    if not force_reload and _model_cache["models"] is not None:
        return _model_cache
    
    print("[ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì¤‘...]")
    
    # ëª¨ë¸ ë¡œë“œ
    _model_cache["models"] = load_fold_models(DEVICE, MODEL_PATHS)
    
    # ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ë¡œë“œ
    with open(WEIGHT_PATH, "r") as f:
        weights_data = json.load(f)
    
    # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì™€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœ ëª¨ë‘ ì§€ì›
    if isinstance(weights_data, list):
        _model_cache["weights"] = weights_data
    elif isinstance(weights_data, dict):
        _model_cache["weights"] = [weights_data[f"fold{i}"] for i in range(1, 6)]
    else:
        raise ValueError(f"Unexpected weights format: {type(weights_data)}")
    
    # ì „ì²˜ë¦¬ ê¸°ì¤€ ë¡œë“œ
    _model_cache["criteria"] = load_criteria(CRITERIA_JSON_PATH)
    
    # LMS ë°ì´í„° ë¡œë“œ
    _model_cache["lms_df"] = load_lms_data(LMS_CSV_PATH)
    
    # Isotonic Calibrator ë¡œë“œ (ìˆëŠ” ê²½ìš°)
    if os.path.exists(ISOTONIC_CALIBRATOR_PATH):
        try:
            from joblib import load as joblib_load
            _model_cache["calibrator"] = joblib_load(ISOTONIC_CALIBRATOR_PATH)
            print(f"[INFO] Isotonic Calibrator ë¡œë“œë¨")
        except Exception as e:
            print(f"[WARN] Isotonic Calibrator ë¡œë“œ ì‹¤íŒ¨: {e}")
            _model_cache["calibrator"] = None
    else:
        print(f"[INFO] Isotonic Calibrator ì—†ìŒ (ê²½ë¡œ: {ISOTONIC_CALIBRATOR_PATH})")
        _model_cache["calibrator"] = None
    
    print("[ë¦¬ì†ŒìŠ¤ ë¡œë“œ ì™„ë£Œ]")
    return _model_cache


# =============================================================================
# ë©”ì¸ ì˜ˆì¸¡ í•¨ìˆ˜ (ì™¸ë¶€ í˜¸ì¶œìš© API)
# =============================================================================
def predict_bone_age(
    image_path: str,
    sex: int,
    height: float,
    age_months: int,
    father_height: float = None,
    mother_height: float = None,
    preprocess_config: dict = None,
    verbose: bool = True
) -> dict:
    """
    ë¼ˆë‚˜ì´ ì˜ˆì¸¡ ë° ì„±ì¸ ì˜ˆìƒí‚¤(PAH) ê³„ì‚°
    
    Parameters:
        image_path (str): ì† X-ray ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        sex (int): ì„±ë³„ (1=ë‚¨ì, 0=ì—¬ì)
        height (float): í˜„ì¬ í‚¤ (cm)
        age_months (int): í˜„ì¬ ë‚˜ì´ (ê°œì›”)
        father_height (float, optional): ì•„ë²„ì§€ í‚¤ (cm). Noneì´ë©´ ìœ ì „ ë³´ì • ë¯¸ì ìš©
        mother_height (float, optional): ì–´ë¨¸ë‹ˆ í‚¤ (cm). Noneì´ë©´ ìœ ì „ ë³´ì • ë¯¸ì ìš©
        preprocess_config (dict, optional): ì „ì²˜ë¦¬ ì„¤ì •. Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        verbose (bool): ìƒì„¸ ì¶œë ¥ ì—¬ë¶€
    
    Returns:
        dict: ì˜ˆì¸¡ ê²°ê³¼ (16ê°œ í•„ë“œ)
            - PAH_Final: ìµœì¢… ì˜ˆì¸¡ í‚¤ (cm)
            - Current_Age: í˜„ì¬ ë‚˜ì´ (Yë…„ Mê°œì›”)
            - BoneAge: ë¼ˆ ë‚˜ì´ (Yë…„ Mê°œì›”)
            - MPH: ìœ ì „ì  ì˜ˆì¸¡ í‚¤ (cm) ë˜ëŠ” None
            - Height_Score: í˜„ì¬ í‚¤ ë°±ë¶„ìœ„ (%)
            - Potential_Score: ì„±ì¥ ì ì¬ë ¥ ì ìˆ˜ (0-100)
            - Current_Height: í˜„ì¬ í‚¤ (cm)
            - Current_Height_Percentile: í˜„ì¬ í‚¤ ë°±ë¶„ìœ„ (%)
            - Genetic_Predicted_Height: ìœ ì „ ê¸°ë°˜ ì˜ˆì¸¡ í‚¤ (cm) ë˜ëŠ” None
            - MPH_Percentile: ìœ ì „ ê¸°ë°˜ ì˜ˆì¸¡ í‚¤ ë°±ë¶„ìœ„ (%) ë˜ëŠ” None
            - Growth_Curve_Predicted_Height: ì„±ì¥ê³¡ì„  ê¸°ë°˜ ì˜ˆì¸¡ í‚¤ (cm)
            - LMS_Percentile: ì„±ì¥ê³¡ì„  ê¸°ë°˜ ì˜ˆì¸¡ í‚¤ ë°±ë¶„ìœ„ (%)
            - Delta_Genetic: ìœ ì „ ê¸°ë°˜ ë³´ì •ëŸ‰ (cm)
            - Delta_Maturity: ì„±ìˆ™ë„ ê¸°ë°˜ ë³´ì •ëŸ‰ (cm)
            - Final_Predicted_Height: ìµœì¢… ì˜ˆì¸¡ í‚¤ (cm)
            - PAH_Final_Percentile: ìµœì¢… ì˜ˆì¸¡ í‚¤ ë°±ë¶„ìœ„ (%)
    
    Example:
        >>> result = predict_bone_age(
        ...     image_path="patient_001.jpg",
        ...     sex=0,
        ...     height=155.0,
        ...     age_months=143,
        ...     father_height=165.0,
        ...     mother_height=156.0
        ... )
        >>> print(result["PAH_Final"])
        158.25
    """
    # ì „ì²˜ë¦¬ ì„¤ì •
    config = DEFAULT_PREPROCESS_CONFIG.copy()
    if preprocess_config:
        config.update(preprocess_config)
    
    if verbose:
        print("=" * 60)
        print("BoneAge + PAH í†µí•© ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
        print("=" * 60)
    
    # ë¦¬ì†ŒìŠ¤ ë¡œë“œ
    resources = load_resources()
    models = resources["models"]
    weights = resources["weights"]
    criteria = resources["criteria"]
    lms_df = resources["lms_df"]
    calibrator = resources["calibrator"]
    
    # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
    if verbose:
        print("\n[STEP 1] ëª¨ë¸ ë¡œë“œ ë° BoneAge ì˜ˆì¸¡...")
    
    img_cur = imread_unicode_color(image_path)
    
    if config["do_standardize"] and config["use_std1"]:
        img_cur = standardize_bgr(img_cur, criteria)
    if config["do_roi"] and config["use_roi1"]:
        roi_bgr, _ = extract_roi_from_image(img_cur)
        if roi_bgr is not None:
            img_cur = roi_bgr
    if config["do_standardize"] and config["use_std2"]:
        img_cur = standardize_bgr(img_cur, criteria)
    if config["do_roi"] and config["use_roi2"]:
        roi_bgr2, _ = extract_roi_from_image(img_cur)
        if roi_bgr2 is not None:
            img_cur = roi_bgr2
    
    # BoneAge ì˜ˆì¸¡ ë° Clamp
    pred_boneage_raw = ensemble_predict_single(img_cur, sex, models, weights, DEVICE)
    pred_boneage_clamped, was_clamped, original_pred = clamp_boneage(pred_boneage_raw, age_months)
    
    if verbose:
        if was_clamped:
            print(f"   âš  BoneAge ë²”ìœ„ ì œí•œ: {original_pred:.2f} â†’ {pred_boneage_clamped:.2f}")
        print(f"   âœ“ BoneAge (ëª¨ë¸): {pred_boneage_clamped:.2f}M ({pred_boneage_clamped/12:.2f}Y)")
    
    # Isotonic Calibration
    boneage_isotonic_calibrated = None
    isotonic_calibration_applied = False
    
    if config["use_isotonic_calibration"] and calibrator is not None:
        if verbose:
            print("\n[Isotonic Calibration]")
        try:
            boneage_isotonic_calibrated = float(calibrator.predict([pred_boneage_clamped])[0])
            boneage_isotonic_delta = boneage_isotonic_calibrated - pred_boneage_clamped
            isotonic_calibration_applied = True
            if verbose:
                print(f"   âœ“ ë³´ì •: {pred_boneage_clamped:.2f} â†’ {boneage_isotonic_calibrated:.2f} ({boneage_isotonic_delta:+.2f})")
        except Exception as e:
            if verbose:
                print(f"   âš  ì‹¤íŒ¨: {e}")
    
    # ìµœì¢… BoneAge ê²°ì •
    if isotonic_calibration_applied and boneage_isotonic_calibrated is not None:
        pred_boneage = boneage_isotonic_calibrated
        if verbose:
            print(f"   â˜… PAH ê³„ì‚°ìš© BoneAge: {pred_boneage:.2f}M (Isotonic)")
    else:
        pred_boneage = pred_boneage_clamped
        if verbose:
            print(f"   â˜… PAH ê³„ì‚°ìš© BoneAge: {pred_boneage:.2f}M")
    
    # LMS ê¸°ë°˜ PAH
    if verbose:
        print("\n[STEP 2] LMS ê¸°ë°˜ PAH ê³„ì‚°...")
    pah_result = calculate_pah_lms(height, pred_boneage, sex, lms_df, ADULT_MONTHS)
    percentile_result = calculate_height_percentile(height, age_months, sex, lms_df)
    if verbose:
        print(f"   âœ“ PAH_LMS: {pah_result['PAH_LMS']:.2f}cm, í˜„ì¬í‚¤ Percentile: {percentile_result['percentile_current']:.1f}th")
    
    # PAH ë³´ì •
    if verbose:
        print("\n[STEP 3] PAH ë³´ì •...")
    calib_result = calibrate_pah(height, pah_result['PAH_LMS'], father_height, mother_height, sex, age_months, pred_boneage)
    if verbose:
        if calib_result['genetic_available']:
            print(f"   âœ“ MPH: {calib_result['MPH']:.2f}cm")
        print(f"   âœ“ PAH_Final: {calib_result['PAH_Final']:.2f}cm")
    
    # ë°±ë¶„ìœ„ ê³„ì‚°
    pah_final_percentile_result = calculate_pah_final_percentile(calib_result['PAH_Final'], sex, lms_df, ADULT_MONTHS)
    
    mph_percentile_result = None
    if calib_result['MPH'] is not None:
        mph_percentile_result = calculate_mph_percentile(calib_result['MPH'], sex, lms_df, ADULT_MONTHS)
    
    pah_lms_percentile_result = calculate_pah_lms_percentile(pah_result['PAH_LMS'], sex, lms_df, ADULT_MONTHS)
    
    # PotentialScore
    potential_result = calculate_potential_score(age_months, pred_boneage)
    if verbose:
        print(f"   âœ“ PotentialScore: {potential_result['potential_score']:.1f}ì  ({potential_result['interpretation']})")
    
    # =============================================================================
    # ìµœì¢… JSON ê²°ê³¼ (16ê°œ í•­ëª©)
    # =============================================================================
    result = {
        "PAH_Final": round(calib_result['PAH_Final'], 2),
        "Current_Age": months_to_year_month_str(age_months),
        "BoneAge": months_to_year_month_str(pred_boneage),
        "MPH": round(calib_result['MPH'], 2) if calib_result['MPH'] is not None else None,
        "Height_Score": round(percentile_result['percentile_current'], 1),
        "Potential_Score": round(potential_result['potential_score'], 1),
        "Current_Height": height,
        "Current_Height_Percentile": round(percentile_result['percentile_current'], 1),
        "Genetic_Predicted_Height": round(calib_result['MPH'], 2) if calib_result['MPH'] is not None else None,
        "MPH_Percentile": round(mph_percentile_result['percentile_mph'], 1) if mph_percentile_result is not None else None,
        "Growth_Curve_Predicted_Height": round(pah_result['PAH_LMS'], 2),
        "LMS_Percentile": round(pah_lms_percentile_result['percentile_pah_lms'], 1),
        "Delta_Genetic": round(calib_result['Î”Genetic'], 2),
        "Delta_Maturity": round(calib_result['Î”Maturity'], 2),
        "Final_Predicted_Height": round(calib_result['PAH_Final'], 2),
        "PAH_Final_Percentile": round(pah_final_percentile_result['percentile_pah_final'], 1),
    }
    
    return result


# =============================================================================
# ë‹¨ë… ì‹¤í–‰ ì‹œ í…ŒìŠ¤íŠ¸
# =============================================================================
if __name__ == "__main__":
    # =========================================================================
    # í…ŒìŠ¤íŠ¸ìš© ì…ë ¥ê°’ ì„¤ì •
    # ì‹¤ì œ ì‚¬ìš© ì‹œ ì•„ë˜ ê°’ë“¤ì„ ë³€ê²½í•˜ì„¸ìš”
    # =========================================================================
    TEST_IMAGE_PATH = os.path.join(PROJECT_ROOT, "Total raw image", "Test Image.jpg")
    TEST_SEX = 0              # 1=ë‚¨ì, 0=ì—¬ì
    TEST_HEIGHT = 155.0       # í˜„ì¬ í‚¤ (cm)
    TEST_AGE_MONTHS = 143     # í˜„ì¬ ë‚˜ì´ (ê°œì›”) - 11ë…„ 11ê°œì›”
    TEST_FATHER_HEIGHT = 165.0  # ì•„ë²„ì§€ í‚¤ (cm), ì—†ìœ¼ë©´ None
    TEST_MOTHER_HEIGHT = 156.0  # ì–´ë¨¸ë‹ˆ í‚¤ (cm), ì—†ìœ¼ë©´ None
    
    # =========================================================================
    # ì˜ˆì¸¡ ì‹¤í–‰
    # =========================================================================
    result = predict_bone_age(
        image_path=TEST_IMAGE_PATH,
        sex=TEST_SEX,
        height=TEST_HEIGHT,
        age_months=TEST_AGE_MONTHS,
        father_height=TEST_FATHER_HEIGHT,
        mother_height=TEST_MOTHER_HEIGHT,
        verbose=True
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ê²°ê³¼")
    print("=" * 60)
    print(f"  ìµœì¢… ì˜ˆì¸¡ í‚¤: {result['PAH_Final']}cm ({result['PAH_Final_Percentile']}th)")
    print(f"  í˜„ì¬ ë‚˜ì´: {result['Current_Age']}")
    print(f"  ë¼ˆ ë‚˜ì´: {result['BoneAge']}")
    print(f"  Potential Score: {result['Potential_Score']}ì ")
    
    # JSON ì €ì¥
    json_output_path = os.path.join(os.path.dirname(TEST_IMAGE_PATH), "prediction_result.json")
    with open(json_output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ“„ JSON ì €ì¥: {json_output_path}")
    
    # JSON ì¶œë ¥
    print("\n" + "=" * 60)
    print("JSON ì¶œë ¥")
    print("=" * 60)
    print(json.dumps(result, ensure_ascii=False, indent=2))
